{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe04d6d1",
      "metadata": {
        "id": "fe04d6d1"
      },
      "source": [
        "## Building Your First RAG System\n",
        "Today's goal is to build a simple Question & Answer bot that can answer questions about a specific, private document that the public GPT model has never seen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cd8ea8f",
      "metadata": {
        "id": "7cd8ea8f"
      },
      "source": [
        "Why We Need RAG\n",
        "First, let's prove the problem we're trying to solve. LLMs have a knowledge cutoff and don't know about your internal company documents.\n",
        "\n",
        "Let's ask our model a question about a fictional company's policy.\n",
        "\n",
        "Cell 1: Setup and Initial Failed Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "251a96cf",
      "metadata": {
        "id": "251a96cf"
      },
      "outputs": [],
      "source": [
        "%pip install ollama numpy faiss-cpu\n",
        "\n",
        "# Note: You might need to restart the kernel after installation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d659d4",
      "metadata": {
        "id": "51d659d4",
        "outputId": "53d50988-87ba-409c-b8dd-32e13d55a702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Switched to local models via Ollama. Ready to build our RAG system!\n"
          ]
        }
      ],
      "source": [
        "import ollama\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "# --- NEW SETUP FOR LOCAL MODELS VIA OLLAMA ---\n",
        "\n",
        "# Helper function for LLM generation\n",
        "def get_llm_response(prompt):\n",
        "    \"\"\"Sends a prompt to the local Llama3 model and returns the response.\"\"\"\n",
        "    response = ollama.chat(\n",
        "        model='llama3',\n",
        "        messages=[{'role': 'user', 'content': prompt}]\n",
        "    )\n",
        "    return response['message']['content']\n",
        "\n",
        "# Helper function for getting embeddings\n",
        "def get_embedding(text, model=\"nomic-embed-text\"):\n",
        "   \"\"\"Generates an embedding for a given text using a local model.\"\"\"\n",
        "   # The model 'nomic-embed-text' is recommended for RAG with Ollama\n",
        "   return ollama.embeddings(model=model, prompt=text)['embedding']\n",
        "\n",
        "print(\"✅ Switched to local models via Ollama. Ready to build our RAG system!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8bf7673",
      "metadata": {
        "id": "d8bf7673"
      },
      "source": [
        "Let's prove why we need RAG. We'll ask the base Llama 3 model a question about a private document it has never seen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbe28fb",
      "metadata": {
        "id": "ffbe28fb",
        "outputId": "700d0ac6-e20b-45c5-85e7-494d88cc2005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Asking a standard LLM a question about a private document ---\n",
            "Question: What is the policy on international travel for remote employees at Innovate Inc.?\n",
            "Response: I'm just an AI, I don't have access to specific company policies. However, I can provide you with some general guidelines that may be applicable to many companies.\n",
            "\n",
            "Innovate Inc., being a fictional company, does not have any real policy on international travel for remote employees. But if it did, the policy might look something like this:\n",
            "\n",
            "**International Travel Policy for Remote Employees at Innovate Inc.**\n",
            "\n",
            "At Innovate Inc., we believe in flexibility and autonomy for our remote employees. However, when traveling internationally, there are certain guidelines and requirements that must be followed to ensure the safety and security of our employees and the company.\n",
            "\n",
            "**Policy Statement:**\n",
            "\n",
            "The following policy outlines the guidelines and procedures for international travel by remote employees at Innovate Inc. The purpose of this policy is to promote safe and responsible international travel while representing the company, as well as to ensure compliance with relevant laws, regulations, and company policies.\n",
            "\n",
            "**Scope:**\n",
            "\n",
            "This policy applies to all remote employees of Innovate Inc. who are required to travel internationally for business purposes.\n",
            "\n",
            "**Guidelines:**\n",
            "\n",
            "1. **Prior Authorization:** All international trips must be approved by the employee's supervisor or manager in advance.\n",
            "2. **Travel Insurance:** Remote employees traveling internationally must have adequate travel insurance coverage that includes medical, trip cancellation, and interruption coverage.\n",
            "3. **Visa Requirements:** Employees are responsible for ensuring they have all necessary visas, permits, and documentation required for their destination country.\n",
            "4. **Security Protocols:** Employees must follow company-approved security protocols when traveling to high-risk destinations or areas of conflict.\n",
            "5. **Travel Arrangements:** Remote employees are expected to make reasonable travel arrangements that minimize costs and ensure efficient use of company resources.\n",
            "6. **Communication:** Employees are required to maintain regular communication with their supervisor or manager while traveling internationally, including reporting any changes in travel plans or unexpected delays.\n",
            "\n",
            "**Additional Requirements:**\n",
            "\n",
            "1. **Travel Declaration:** All remote employees traveling internationally must complete a travel declaration form prior to departure, which will include information about their itinerary, destination country, and contact information.\n",
            "2. **Safety Precautions:** Employees are expected to take reasonable safety precautions while traveling, including carrying personal identification documents, maintaining situational awareness, and reporting any incidents or concerns.\n",
            "\n",
            "**Compliance:**\n",
            "\n",
            "All remote employees traveling internationally must comply with this policy and any additional requirements outlined in the company's travel guidelines. Failure to comply may result in disciplinary action up to and including termination of employment.\n",
            "\n",
            "**Amendments:**\n",
            "\n",
            "This policy is subject to change at any time without notice. Remote employees are responsible for reviewing and understanding any updates or amendments to this policy.\n",
            "\n",
            "I hope this example policy helps you understand what a company's international travel policy might look like. Remember that actual policies may vary depending on the company, industry, and location.\n"
          ]
        }
      ],
      "source": [
        "# ---- The Question ----\n",
        "question = \"What is the policy on international travel for remote employees at Innovate Inc.?\"\n",
        "\n",
        "print(\"--- Asking a standard LLM a question about a private document ---\")\n",
        "response = get_llm_response(question)\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Response: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa88a43a",
      "metadata": {
        "id": "fa88a43a"
      },
      "source": [
        "## The Knowledge Base & Chunking\n",
        "A RAG system needs a source of truth. For this lab, our knowledge base will be a single document. Since LLMs have a context limit, we must break down our document into smaller, manageable \"chunks.\"\n",
        "\n",
        "Cell 2: Creating Our Knowledge Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71a26f9",
      "metadata": {
        "id": "b71a26f9",
        "outputId": "37854248-16f4-48e3-9d0d-ed310fd25e24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We have broken the document into 6 chunks.\n",
            "--- Chunk 1 ---\n",
            "\n",
            "Innovate Inc. Remote Work Policy - Effective 2025\n",
            "--- Chunk 2 ---\n",
            "1. Eligibility: All employees with roles that can be performed outside of a traditional office are eligible for remote work, subject to manager approval. This includes software engineers, marketers, and customer support staff.\n",
            "--- Chunk 3 ---\n",
            "2. Work Hours: Remote employees are expected to be available during the core business hours of 10:00 AM to 4:00 PM in their local time zone. A flexible approach is encouraged to accommodate different working styles.\n",
            "--- Chunk 4 ---\n",
            "3. Equipment: The company will provide a standard remote work package, including a laptop, monitor, and a one-time stipend of $500 for home office setup. Employees are responsible for maintaining a reliable high-speed internet connection.\n",
            "--- Chunk 5 ---\n",
            "4. International Travel: Remote employees wishing to work from a different country for more than 30 consecutive days must obtain approval from both their direct manager and HR. The request must be submitted at least 60 days in advance to assess tax and legal implications. Short-term travel under 30 days does not require pre-approval but should be communicated to the manager.\n",
            "--- Chunk 6 ---\n",
            "5. Performance: Performance for remote employees will be measured using the same standards as in-office employees, focusing on output, goal achievement, and contribution to team success.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Our private knowledge base - a fictional company's remote work policy.\n",
        "document_text = \"\"\"\n",
        "Innovate Inc. Remote Work Policy - Effective 2025\n",
        "\n",
        "1. Eligibility: All employees with roles that can be performed outside of a traditional office are eligible for remote work, subject to manager approval. This includes software engineers, marketers, and customer support staff.\n",
        "\n",
        "2. Work Hours: Remote employees are expected to be available during the core business hours of 10:00 AM to 4:00 PM in their local time zone. A flexible approach is encouraged to accommodate different working styles.\n",
        "\n",
        "3. Equipment: The company will provide a standard remote work package, including a laptop, monitor, and a one-time stipend of $500 for home office setup. Employees are responsible for maintaining a reliable high-speed internet connection.\n",
        "\n",
        "4. International Travel: Remote employees wishing to work from a different country for more than 30 consecutive days must obtain approval from both their direct manager and HR. The request must be submitted at least 60 days in advance to assess tax and legal implications. Short-term travel under 30 days does not require pre-approval but should be communicated to the manager.\n",
        "\n",
        "5. Performance: Performance for remote employees will be measured using the same standards as in-office employees, focusing on output, goal achievement, and contribution to team success.\n",
        "\"\"\"\n",
        "\n",
        "# Simple Chunking Strategy: Split the document by paragraphs (double newlines)\n",
        "text_chunks = document_text.split('\\n\\n')\n",
        "\n",
        "print(f\"We have broken the document into {len(text_chunks)} chunks.\")\n",
        "for i, chunk in enumerate(text_chunks):\n",
        "    print(f\"--- Chunk {i+1} ---\\n{chunk}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a4c39bf",
      "metadata": {
        "id": "2a4c39bf"
      },
      "source": [
        "### Part 2: The \"Retrieval\" - Local Embeddings and Vector Store\n",
        "Now for the core of RAG. We'll use our local nomic-embed-text model to convert the text chunks into embeddings and store them in our FAISS vector database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae00d5a",
      "metadata": {
        "id": "cae00d5a",
        "outputId": "5a3ef3a8-2c48-4b2d-dde6-378a6b84e57d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index created with 6 vectors of dimension 768.\n"
          ]
        }
      ],
      "source": [
        "# Generate embeddings for each text chunk using our local model\n",
        "chunk_embeddings = [get_embedding(chunk) for chunk in text_chunks]\n",
        "\n",
        "# Convert to a NumPy array for FAISS\n",
        "embedding_matrix = np.array(chunk_embeddings).astype('float32')\n",
        "\n",
        "# Create a FAISS index\n",
        "# d is the dimension of our embeddings (768 for nomic-embed-text)\n",
        "d = embedding_matrix.shape[1]\n",
        "index = faiss.IndexFlatL2(d)\n",
        "\n",
        "# Add our chunk embeddings to the index\n",
        "index.add(embedding_matrix)\n",
        "\n",
        "print(f\"FAISS index created with {index.ntotal} vectors of dimension {d}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22626004",
      "metadata": {
        "id": "22626004"
      },
      "source": [
        "## The \"Augmented Generation\"\n",
        "We're ready to answer our user's question! The process is:\n",
        "\n",
        "Take the user's question and convert it into an embedding.\n",
        "\n",
        "Use our FAISS index to find the most similar chunk(s) from our knowledge base.\n",
        "\n",
        "Combine the original question with the retrieved chunk(s) into a new, \"augmented\" prompt.\n",
        "\n",
        "Send this rich prompt to the LLM to get a grounded, accurate answer.\n",
        "\n",
        "Cell 4: RAG in Action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0858739",
      "metadata": {
        "id": "a0858739",
        "outputId": "5e04874a-2794-4627-979f-6e8721137647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Most relevant chunk found ---\n",
            "\n",
            "Innovate Inc. Remote Work Policy - Effective 2025\n",
            "\n",
            "--- Sending Augmented Prompt to Local LLM ---\n",
            "\n",
            "Question: What is the policy on international travel for remote employees at Innovate Inc.?\n",
            "Grounded Response: Based on the provided context, I can inform you that there is no specific policy mentioned regarding international travel for remote employees at Innovate Inc.\n",
            "\n",
            "Since we don't have enough information to answer this question specifically, my response would be: \"I don't have enough information.\" If you'd like to know more about this topic or any other HR-related matters, please let me know and I'll do my best to assist you!\n"
          ]
        }
      ],
      "source": [
        "# The same question as before\n",
        "question = \"What is the policy on international travel for remote employees at Innovate Inc.?\"\n",
        "\n",
        "# 1. Embed the user's question using our local model\n",
        "question_embedding = np.array([get_embedding(question)]).astype('float32')\n",
        "\n",
        "# 2. Search the FAISS index for the most relevant chunk\n",
        "k = 1\n",
        "distances, indices = index.search(question_embedding, k)\n",
        "\n",
        "# Get the most relevant chunk of text\n",
        "retrieved_chunk = text_chunks[indices[0][0]]\n",
        "\n",
        "print(f\"--- Most relevant chunk found ---\\n{retrieved_chunk}\")\n",
        "\n",
        "# 3. Assemble the augmented prompt\n",
        "augmented_prompt = f\"\"\"\n",
        "You are a helpful HR assistant. Answer the user's question based ONLY on the following context.\n",
        "If the context doesn't contain the answer, say that you don't have enough information.\n",
        "\n",
        "Context:\n",
        "---\n",
        "{retrieved_chunk}\n",
        "---\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n--- Sending Augmented Prompt to Local LLM ---\")\n",
        "# 4. Send to Llama 3 and get the final, grounded answer\n",
        "rag_response = get_llm_response(augmented_prompt)\n",
        "\n",
        "print(f\"\\nQuestion: {question}\")\n",
        "print(f\"Grounded Response: {rag_response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fef69aaa",
      "metadata": {
        "id": "fef69aaa"
      },
      "source": [
        " By providing the LLM with the right information at the right time, it was able to answer our specific question perfectly. You have just successfully built a complete, end-to-end RAG system."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}